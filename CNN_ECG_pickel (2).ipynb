{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9pIENHhWZ7S",
        "outputId": "13b45d98-bfe3-4dd1-9456-bdb83852d931"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.1)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.6.15)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opencv-contrib-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNcr1UT1WZrM",
        "outputId": "680c3e6e-c791-4d3e-c2b7-859d86f7ed0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.11/dist-packages (from opencv-contrib-python) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "jbfuDw01u1vN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ln58PrggV3IG"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Preprocessing function\n",
        "def preprocess_image(image_path, target_size=(128, 128)):\n",
        "    # 1. Convert to grayscale\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # 2. Resize image\n",
        "    img = cv2.resize(img, target_size)\n",
        "\n",
        "    # 3. Normalize pixel values to [0,1]\n",
        "    img = img.astype('float32') / 255.0\n",
        "\n",
        "    # Add channel dimension for CNN\n",
        "    img = np.expand_dims(img, axis=-1)\n",
        "    return img\n",
        "\n",
        "# Load and preprocess dataset\n",
        "def load_dataset(data_dir, target_size=(128, 128)):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    # Define folder paths and corresponding labels\n",
        "    folders = [\n",
        "        ('Normal Person ECG Images (284x12=3408)', 0),  # Normal\n",
        "        ('ECG Images of Myocardial Infarction Patients (240x12=2880)', 1),  # MI\n",
        "        ('ECG Images of Patient that have History of MI (172x12=2064)', 2),  # History of MI\n",
        "        ('ECG Images of Patient that have abnormal heartbeat (233x12=2796)', 3)  # Abnormal Heartbeat\n",
        "    ]\n",
        "\n",
        "    # Load images from each folder\n",
        "    for folder_name, label in folders:\n",
        "        folder_path = os.path.join(data_dir, folder_name)\n",
        "        for img_name in os.listdir(folder_path):\n",
        "            img_path = os.path.join(folder_path, img_name)\n",
        "            img = preprocess_image(img_path, target_size)\n",
        "            images.append(img)\n",
        "            labels.append(label)\n",
        "\n",
        "    # Convert to arrays and one-hot encode labels\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "    labels = to_categorical(labels, num_classes=4)\n",
        "\n",
        "    return images, labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U_Lsn-tIu_jt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WUsar5CWtrQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic CNN Model\n",
        "def build_cnn_model(input_shape=(128, 128, 1)):\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(4, activation='softmax')  # Multi-class classification\n",
        "    ])\n",
        "    model.compile(optimizer='adam',\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "tvcPV9JWXOFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convolutional Autoencoder for feature extraction\n",
        "def build_autoencoder(input_shape=(128, 128, 1)):\n",
        "    # Encoder\n",
        "    input_img = layers.Input(shape=input_shape)\n",
        "    x = layers.Conv2D(32, (3, 3), activation='relu', strides = (1,1), padding='same')(input_img)\n",
        "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "    x = layers.Conv2D(16, (3, 3), activation='relu', strides = (1,1), padding='same')(x)\n",
        "    encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "    # Decoder\n",
        "    x = layers.Conv2D(16, (3, 3), activation='relu', strides = (1,1), padding='same')(encoded)\n",
        "    x = layers.UpSampling2D((2, 2))(x)\n",
        "    x = layers.Conv2D(32, (3, 3), activation='relu', strides = (1,1), padding='same')(x)\n",
        "    x = layers.UpSampling2D((2, 2))(x)\n",
        "    decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "    autoencoder = models.Model(input_img, decoded)\n",
        "    autoencoder.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "    # Encoder model for feature extraction\n",
        "    encoder = models.Model(input_img, encoded)\n",
        "    return autoencoder, encoder"
      ],
      "metadata": {
        "id": "XjBjUNohtsjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification model using autoencoder features\n",
        "def build_classifier_from_autoencoder(encoder, input_shape=(32, 32, 16)):\n",
        "    model = models.Sequential([\n",
        "        encoder,\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(4, activation='softmax')  # Multi-class classification\n",
        "    ])\n",
        "    model.compile(optimizer='adam',\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "UKxJ9g6LtsgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main execution\n",
        "if __name__ == '__main__':\n",
        "    # Set dataset directory\n",
        "    data_dir = '/content/drive/MyDrive/ecg major/major ecg updated/train'\n",
        "    images, labels = load_dataset(data_dir)\n",
        "\n",
        "    # Split dataset\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        images, labels, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Train basic CNN\n",
        "    cnn_model = build_cnn_model()\n",
        "    cnn_history = cnn_model.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=20,\n",
        "        batch_size=32,\n",
        "        validation_data=(X_test, y_test)\n",
        "    )\n",
        "\n",
        "    # Save CNN model to pickle file\n",
        "    with open('cnn_model.pkl', 'wb') as f:\n",
        "        pickle.dump(cnn_model, f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwv4UhtWtsaQ",
        "outputId": "7cf15786-e9f1-42b9-f05a-42ed72b85978"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 817ms/step - accuracy: 0.2637 - loss: 2.1223 - val_accuracy: 0.2796 - val_loss: 1.3823\n",
            "Epoch 2/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 700ms/step - accuracy: 0.2566 - loss: 1.3801 - val_accuracy: 0.2796 - val_loss: 1.3821\n",
            "Epoch 3/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 697ms/step - accuracy: 0.3053 - loss: 1.3764 - val_accuracy: 0.2796 - val_loss: 1.3739\n",
            "Epoch 4/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 697ms/step - accuracy: 0.3008 - loss: 1.3839 - val_accuracy: 0.2796 - val_loss: 1.3761\n",
            "Epoch 5/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 697ms/step - accuracy: 0.3164 - loss: 1.3670 - val_accuracy: 0.2903 - val_loss: 1.3561\n",
            "Epoch 6/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 697ms/step - accuracy: 0.3704 - loss: 1.3202 - val_accuracy: 0.2581 - val_loss: 1.4917\n",
            "Epoch 7/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 677ms/step - accuracy: 0.4286 - loss: 1.2704 - val_accuracy: 0.5591 - val_loss: 1.0824\n",
            "Epoch 8/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 679ms/step - accuracy: 0.5876 - loss: 0.9827 - val_accuracy: 0.6559 - val_loss: 0.8677\n",
            "Epoch 9/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 696ms/step - accuracy: 0.6882 - loss: 0.7730 - val_accuracy: 0.7258 - val_loss: 0.6732\n",
            "Epoch 10/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 671ms/step - accuracy: 0.8078 - loss: 0.5300 - val_accuracy: 0.6989 - val_loss: 0.6430\n",
            "Epoch 11/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 679ms/step - accuracy: 0.8019 - loss: 0.4879 - val_accuracy: 0.8011 - val_loss: 0.5000\n",
            "Epoch 12/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 657ms/step - accuracy: 0.8693 - loss: 0.3333 - val_accuracy: 0.8656 - val_loss: 0.3250\n",
            "Epoch 13/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 671ms/step - accuracy: 0.9461 - loss: 0.1644 - val_accuracy: 0.8333 - val_loss: 0.3708\n",
            "Epoch 14/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 674ms/step - accuracy: 0.9527 - loss: 0.1347 - val_accuracy: 0.8871 - val_loss: 0.3396\n",
            "Epoch 15/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 693ms/step - accuracy: 0.9601 - loss: 0.1031 - val_accuracy: 0.9194 - val_loss: 0.2280\n",
            "Epoch 16/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 680ms/step - accuracy: 0.9838 - loss: 0.0609 - val_accuracy: 0.8602 - val_loss: 0.3649\n",
            "Epoch 17/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 671ms/step - accuracy: 0.9722 - loss: 0.1109 - val_accuracy: 0.9194 - val_loss: 0.2498\n",
            "Epoch 18/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 649ms/step - accuracy: 0.9961 - loss: 0.0248 - val_accuracy: 0.9301 - val_loss: 0.2364\n",
            "Epoch 19/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 666ms/step - accuracy: 1.0000 - loss: 0.0147 - val_accuracy: 0.9355 - val_loss: 0.2304\n",
            "Epoch 20/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 679ms/step - accuracy: 0.9986 - loss: 0.0071 - val_accuracy: 0.9301 - val_loss: 0.2788\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train autoencoder\n",
        "autoencoder, encoder = build_autoencoder()\n",
        "autoencoder.fit(\n",
        "        X_train, X_train,  # Autoencoder reconstructs input\n",
        "        epochs=20,\n",
        "        batch_size=32,\n",
        "        validation_data=(X_test, X_test)\n",
        "  )\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8itAMNbGtsXC",
        "outputId": "43956c8c-63a1-4ff1-f45a-a243d8b2f5ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1s/step - loss: 0.1226 - val_loss: 0.0226\n",
            "Epoch 2/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1s/step - loss: 0.0225 - val_loss: 0.0226\n",
            "Epoch 3/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1s/step - loss: 0.0225 - val_loss: 0.0226\n",
            "Epoch 4/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1s/step - loss: 0.0226 - val_loss: 0.0226\n",
            "Epoch 5/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1s/step - loss: 0.0226 - val_loss: 0.0226\n",
            "Epoch 6/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1s/step - loss: 0.0225 - val_loss: 0.0226\n",
            "Epoch 7/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1s/step - loss: 0.0225 - val_loss: 0.0226\n",
            "Epoch 8/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1s/step - loss: 0.0226 - val_loss: 0.0226\n",
            "Epoch 9/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - loss: 0.0224 - val_loss: 0.0226\n",
            "Epoch 10/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - loss: 0.0227 - val_loss: 0.0226\n",
            "Epoch 11/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - loss: 0.0226 - val_loss: 0.0226\n",
            "Epoch 12/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - loss: 0.0224 - val_loss: 0.0226\n",
            "Epoch 13/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - loss: 0.0222 - val_loss: 0.0226\n",
            "Epoch 14/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - loss: 0.0225 - val_loss: 0.0226\n",
            "Epoch 15/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - loss: 0.0225 - val_loss: 0.0226\n",
            "Epoch 16/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1s/step - loss: 0.0224 - val_loss: 0.0226\n",
            "Epoch 17/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - loss: 0.0225 - val_loss: 0.0226\n",
            "Epoch 18/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - loss: 0.0224 - val_loss: 0.0226\n",
            "Epoch 19/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1s/step - loss: 0.0226 - val_loss: 0.0226\n",
            "Epoch 20/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1s/step - loss: 0.0224 - val_loss: 0.0226\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d6814115c10>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train classifier with autoencoder features\n",
        "classifier = build_classifier_from_autoencoder(encoder)\n",
        "classifier.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=20,\n",
        "        batch_size=32,\n",
        "        validation_data=(X_test, y_test)\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4e71qM6uAAE",
        "outputId": "27432bc1-0c3b-472d-df9c-e9a790a1644f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 457ms/step - accuracy: 0.2915 - loss: 4.4214 - val_accuracy: 0.1828 - val_loss: 1.3869\n",
            "Epoch 2/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 440ms/step - accuracy: 0.2290 - loss: 1.4203 - val_accuracy: 0.2581 - val_loss: 1.3859\n",
            "Epoch 3/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 432ms/step - accuracy: 0.2523 - loss: 1.3856 - val_accuracy: 0.2796 - val_loss: 1.3849\n",
            "Epoch 4/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 427ms/step - accuracy: 0.2783 - loss: 1.3844 - val_accuracy: 0.2796 - val_loss: 1.3838\n",
            "Epoch 5/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 421ms/step - accuracy: 0.3183 - loss: 1.3829 - val_accuracy: 0.2796 - val_loss: 1.3827\n",
            "Epoch 6/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 431ms/step - accuracy: 0.3310 - loss: 1.3804 - val_accuracy: 0.2796 - val_loss: 1.3817\n",
            "Epoch 7/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 436ms/step - accuracy: 0.3199 - loss: 1.3799 - val_accuracy: 0.2796 - val_loss: 1.3808\n",
            "Epoch 8/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 423ms/step - accuracy: 0.3258 - loss: 1.3791 - val_accuracy: 0.2796 - val_loss: 1.3802\n",
            "Epoch 9/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 419ms/step - accuracy: 0.3057 - loss: 1.3788 - val_accuracy: 0.2796 - val_loss: 1.3796\n",
            "Epoch 10/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 417ms/step - accuracy: 0.3212 - loss: 1.3762 - val_accuracy: 0.2796 - val_loss: 1.3790\n",
            "Epoch 11/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 423ms/step - accuracy: 0.2887 - loss: 1.3795 - val_accuracy: 0.2796 - val_loss: 1.3785\n",
            "Epoch 12/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 422ms/step - accuracy: 0.3358 - loss: 1.3749 - val_accuracy: 0.2796 - val_loss: 1.3782\n",
            "Epoch 13/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 427ms/step - accuracy: 0.3252 - loss: 1.3772 - val_accuracy: 0.2796 - val_loss: 1.3779\n",
            "Epoch 14/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 427ms/step - accuracy: 0.3183 - loss: 1.3736 - val_accuracy: 0.2796 - val_loss: 1.3775\n",
            "Epoch 15/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 414ms/step - accuracy: 0.3122 - loss: 1.3730 - val_accuracy: 0.2796 - val_loss: 1.3770\n",
            "Epoch 16/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 409ms/step - accuracy: 0.2939 - loss: 1.3750 - val_accuracy: 0.2796 - val_loss: 1.3767\n",
            "Epoch 17/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 423ms/step - accuracy: 0.3117 - loss: 1.3715 - val_accuracy: 0.2796 - val_loss: 1.3765\n",
            "Epoch 18/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 414ms/step - accuracy: 0.3212 - loss: 1.3730 - val_accuracy: 0.2796 - val_loss: 1.3764\n",
            "Epoch 19/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 431ms/step - accuracy: 0.2879 - loss: 1.3789 - val_accuracy: 0.2796 - val_loss: 1.3763\n",
            "Epoch 20/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 414ms/step - accuracy: 0.3131 - loss: 1.3710 - val_accuracy: 0.2796 - val_loss: 1.3763\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d6823d33b10>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Train tuned classifier with autoencoder features\n",
        "classifier1 = build_classifier_from_autoencoder(encoder)\n",
        "classifier1.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=30,\n",
        "        batch_size=32,\n",
        "        validation_data=(X_test, y_test)\n",
        "    )\n",
        "\n",
        "    # Save tuned classifier to pickle file\n",
        "with open('classifier1.pkl', 'wb') as f:\n",
        "  pickle.dump(classifier1, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRT5yXhUt_6e",
        "outputId": "03fd5ad2-506e-43ea-c945-7b67156fdaf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 453ms/step - accuracy: 0.2952 - loss: 3.4432 - val_accuracy: 0.4355 - val_loss: 1.1904\n",
            "Epoch 2/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 431ms/step - accuracy: 0.5621 - loss: 1.1016 - val_accuracy: 0.7043 - val_loss: 0.9824\n",
            "Epoch 3/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 419ms/step - accuracy: 0.7305 - loss: 0.8697 - val_accuracy: 0.7258 - val_loss: 0.7633\n",
            "Epoch 4/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 422ms/step - accuracy: 0.8250 - loss: 0.5762 - val_accuracy: 0.8011 - val_loss: 0.5683\n",
            "Epoch 5/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 419ms/step - accuracy: 0.8868 - loss: 0.4317 - val_accuracy: 0.8387 - val_loss: 0.4767\n",
            "Epoch 6/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 418ms/step - accuracy: 0.8941 - loss: 0.3439 - val_accuracy: 0.8871 - val_loss: 0.3665\n",
            "Epoch 7/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 417ms/step - accuracy: 0.9442 - loss: 0.2340 - val_accuracy: 0.8817 - val_loss: 0.3541\n",
            "Epoch 8/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 423ms/step - accuracy: 0.9707 - loss: 0.1820 - val_accuracy: 0.9086 - val_loss: 0.2940\n",
            "Epoch 9/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 427ms/step - accuracy: 0.9847 - loss: 0.1303 - val_accuracy: 0.9194 - val_loss: 0.2612\n",
            "Epoch 10/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 432ms/step - accuracy: 0.9719 - loss: 0.1223 - val_accuracy: 0.8871 - val_loss: 0.3058\n",
            "Epoch 11/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 427ms/step - accuracy: 0.9747 - loss: 0.1105 - val_accuracy: 0.9086 - val_loss: 0.2646\n",
            "Epoch 12/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 440ms/step - accuracy: 0.9835 - loss: 0.0784 - val_accuracy: 0.9086 - val_loss: 0.2393\n",
            "Epoch 13/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 431ms/step - accuracy: 0.9927 - loss: 0.0458 - val_accuracy: 0.9301 - val_loss: 0.2121\n",
            "Epoch 14/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 431ms/step - accuracy: 0.9945 - loss: 0.0359 - val_accuracy: 0.9194 - val_loss: 0.2052\n",
            "Epoch 15/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 423ms/step - accuracy: 0.9962 - loss: 0.0323 - val_accuracy: 0.9301 - val_loss: 0.2056\n",
            "Epoch 16/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 417ms/step - accuracy: 1.0000 - loss: 0.0262 - val_accuracy: 0.9301 - val_loss: 0.2038\n",
            "Epoch 17/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 431ms/step - accuracy: 0.9994 - loss: 0.0206 - val_accuracy: 0.9247 - val_loss: 0.1909\n",
            "Epoch 18/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 423ms/step - accuracy: 0.9986 - loss: 0.0242 - val_accuracy: 0.9355 - val_loss: 0.1908\n",
            "Epoch 19/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 426ms/step - accuracy: 1.0000 - loss: 0.0139 - val_accuracy: 0.9140 - val_loss: 0.2134\n",
            "Epoch 20/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 418ms/step - accuracy: 1.0000 - loss: 0.0107 - val_accuracy: 0.9194 - val_loss: 0.2402\n",
            "Epoch 21/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 444ms/step - accuracy: 1.0000 - loss: 0.0132 - val_accuracy: 0.9301 - val_loss: 0.2081\n",
            "Epoch 22/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 436ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 0.9247 - val_loss: 0.2029\n",
            "Epoch 23/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 440ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.9301 - val_loss: 0.2474\n",
            "Epoch 24/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 435ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.9247 - val_loss: 0.2062\n",
            "Epoch 25/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 435ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.9301 - val_loss: 0.2152\n",
            "Epoch 26/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 435ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.9355 - val_loss: 0.2192\n",
            "Epoch 27/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 418ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.9355 - val_loss: 0.2254\n",
            "Epoch 28/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 432ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.9301 - val_loss: 0.2082\n",
            "Epoch 29/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 432ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9247 - val_loss: 0.2278\n",
            "Epoch 30/30\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 430ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9355 - val_loss: 0.2146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Default title text\n",
        "print(\"Basic CNN Test Accuracy:\", f\"{cnn_score[1]:.4f}\")\n",
        "print(\"Improved Convolutional Autoencoder Test Accuracy:\", f\"{ae_score[1]:.4f}\")\n",
        "print(\"Tuned Convolutional Autoencoder Test Accuracy:\", f\"{tuned_ae_score[1]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-nm-YuOt_3t",
        "outputId": "7e96f27c-087c-49e0-ab16-28ecd1c16b72"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Basic CNN Test Accuracy: 0.8541\n",
            "Improved Convolutional Autoencoder Test Accuracy: 0.8750\n",
            "Tuned Convolutional Autoencoder Test Accuracy: 0.9255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "biJn2j0b7nwg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}